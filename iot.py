# -*- coding: utf-8 -*-
"""iot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rPHONBmtq2zSvPjUhqjYjZ-x2fyFy1dA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
from google.colab import files
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

uploaded = files.upload()
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)
print("Dataset Loaded Successfully!")
print(df.head())

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from google.colab import files

# Step 1: Upload dataset manually
uploaded = files.upload()
df = pd.read_csv(next(iter(uploaded)))

# Step 2: Normalize column names (fix case, spaces, special characters)
df.columns = df.columns.str.lower().str.strip().str.replace(" ", "_")

# Step 3: Verify column names after cleanup
print(df.columns)

# Step 4: Now access 'gender' safely
if 'gender' in df.columns:
    print(df['gender'].head())  # Print first few values
else:
    print("Column 'gender' not found in the dataset!")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from google.colab import files

# Step 1: Upload Dataset
uploaded = files.upload()
df = pd.read_csv(next(iter(uploaded)))

# Step 2: Clean Column Names
df.columns = df.columns.str.lower().str.strip().str.replace(" ", "_")

# Step 3: Convert Categorical Data
df['gender'] = df['gender'].astype('category').cat.codes
df['admission_type'] = df['admission_type'].astype('category').cat.codes
df['insurance_provider'] = df['insurance_provider'].astype('category').cat.codes
df['test_results'] = df['test_results'].astype('category').cat.codes  # Target variable

# Step 4: Check for Missing Values
df.fillna(df.mean(), inplace=True)

# Step 5: Visualizing Data Trends
plt.figure(figsize=(10, 5))
sns.boxplot(x='age', y='heart_rate', data=df)
plt.title("Heart Rate vs Age Distribution")
plt.show()

plt.figure(figsize=(10, 5))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

# Step 6: Split Data for Machine Learning
X = df[['age', 'gender', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature']]
y = df['test_results']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Train Model (RandomForestClassifier)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 8: Model Evaluation
y_pred = model.predict(X_test)
print("Accuracy Score:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Step 9: Display Feature Importance
feature_importances = pd.Series(model.feature_importances_, index=X.columns)
feature_importances.sort_values(ascending=False).plot(kind='bar', title="Feature Importance in Predicting Test Results")
plt.show()

# Fill numeric columns with mean values
df.fillna(df.select_dtypes(include=['number']).mean(), inplace=True)

# Fill categorical columns with mode (most frequent value)
df.fillna(df.select_dtypes(include=['object']).mode().iloc[0], inplace=True)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Upload and Load Dataset
from google.colab import files
uploaded = files.upload()

df = pd.read_csv(list(uploaded.keys())[0])

# Step 2: Display Basic Information
print("Dataset Shape:", df.shape)
print("\nColumn Names:\n", df.columns)
print("\nFirst Five Rows:\n", df.head())

# Step 3: Convert Data Types if Necessary
numeric_cols = ['age', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature', 'length_of_stay', 'billing_amount']
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

# Step 4: Check and Handle Missing Values
df.fillna(df.median(), inplace=True)

# Step 5: Visualizing Data Trends
plt.figure(figsize=(10, 6))
sns.histplot(df['age'], bins=30, kde=True)
plt.title('Age Distribution of Patients')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='admission_type', y='billing_amount', data=df)
plt.title('Billing Amount by Admission Type')
plt.xticks(rotation=45)
plt.show()

# Step 6: Analyze Critical Patients
critical_patients = df[(df['heart_rate'] > 100) | (df['blood_pressure'] > 150) | (df['oxygen_level'] < 90)]
print("\nCritical Patients Count:", critical_patients.shape[0])

# Step 7: Average Hospital Stay Analysis
avg_stay = df.groupby('hospital_id')['length_of_stay'].mean().reset_index()
print("\nAverage Length of Stay Per Hospital:\n", avg_stay.head())

# Step 8: Insurance Provider Billing Summary
insurance_summary = df.groupby('insurance_provider')['billing_amount'].agg(['mean', 'sum', 'count'])
print("\nInsurance Provider Billing Summary:\n", insurance_summary)

# Step 9: Detecting IoT Sensor Data Anomalies
df['abnormal_heart_rate'] = df['heart_rate'].apply(lambda x: 1 if x > 120 or x < 50 else 0)
df['abnormal_oxygen'] = df['oxygen_level'].apply(lambda x: 1 if x < 92 else 0)

abnormal_cases = df[(df['abnormal_heart_rate'] == 1) | (df['abnormal_oxygen'] == 1)]
print("\nDetected Abnormal Sensor Readings:\n", abnormal_cases.head())

# Step 10: Generate Final Summary
print("\n--- IoT Patient Monitoring Summary ---")
print("Total Patients:", df.shape[0])
print("Critical Patients:", critical_patients.shape[0])
print("Abnormal IoT Sensor Readings:", abnormal_cases.shape[0])
print("\n--- Analysis Completed Successfully ---")

# Save processed dataset
df.to_csv("processed_iot_patient_monitoring.csv", index=False)
print("Processed dataset saved successfully!")

print("Actual Column Names in Dataset:", df.columns.tolist())

numeric_cols = ['Age', 'Heart_Rate', 'Blood_Pressure', 'Oxygen_Level', 'Temperature', 'Length_of_Stay', 'Billing_Amount']

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Upload and Load Dataset
from google.colab import files
uploaded = files.upload()

df = pd.read_csv(list(uploaded.keys())[0])

# Step 2: Standardize Column Names (remove spaces, lowercase)
df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")

# Step 3: Display Corrected Column Names
print("Updated Column Names:", df.columns.tolist())

# Step 4: Convert Numeric Columns Properly
numeric_cols = ['age', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature', 'length_of_stay', 'billing_amount']
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

# Step 5: Handle Missing Values
df.fillna(df.median(), inplace=True)

# Step 6: Check Dataset Summary
print(df.info())

# Step 7: Visualization - Heart Rate Distribution
plt.figure(figsize=(10, 6))
sns.histplot(df['heart_rate'], bins=30, kde=True)
plt.title('Heart Rate Distribution of Patients')
plt.xlabel('Heart Rate')
plt.ylabel('Count')
plt.show()

# Select only numeric columns for median imputation
numeric_cols = ['age', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature', 'length_of_stay', 'billing_amount']

# Apply median imputation only to numeric columns
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')  # Ensure numeric conversion
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())  # Fill missing values with median

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Upload and Load Dataset
from google.colab import files
uploaded = files.upload()

df = pd.read_csv(list(uploaded.keys())[0])

# Step 2: Standardize Column Names (remove spaces, lowercase)
df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")

# Step 3: Display Corrected Column Names
print("Updated Column Names:", df.columns.tolist())

# Step 4: Convert Numeric Columns Properly
numeric_cols = ['age', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature', 'length_of_stay', 'billing_amount']
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

# Step 5: Handle Missing Values
df.fillna(df.median(), inplace=True)

# Step 6: Check Dataset Summary
print(df.info())

# Step 7: Visualization - Heart Rate Distribution
plt.figure(figsize=(10, 6))
sns.histplot(df['heart_rate'], bins=30, kde=True)
plt.title('Heart Rate Distribution of Patients')
plt.xlabel('Heart Rate')
plt.ylabel('Count')
plt.show()

# Handle missing values separately for numerical and categorical columns
num_cols = ['age', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature', 'length_of_stay', 'billing_amount']
cat_cols = ['gender', 'movement_activity', 'admission_type', 'insurance_provider', 'test_results']

# Fill missing values in numerical columns with the median
df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')  # Ensure numerical type
df[num_cols] = df[num_cols].fillna(df[num_cols].median())

# Fill missing values in categorical columns with the most common (mode)
df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])

# Display basic information about the dataset
print("Dataset Summary:\n", df.info())

# Show the first few rows of the dataset
print("\nFirst 5 Rows:\n", df.head())

# Describe numerical features
print("\nStatistical Summary:\n", df.describe())

# Count of unique values in categorical columns
print("\nCategorical Data Overview:\n", df[cat_cols].nunique())

"""**Histogram (Age Distribution)** → Showed patient age patterns."""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.histplot(df['age'], bins=20, kde=True, color='blue')
plt.title('Distribution of Patient Ages')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

"""**Count Plots (Gender, Admission Type, etc.)** → Displayed categorical data distributions."""

plt.figure(figsize=(6,4))
sns.countplot(x=df['gender'], palette='coolwarm')
plt.title("Gender Distribution of Patients")
plt.xlabel("Gender")
plt.ylabel("Count")
plt.show()

"""**Correlation Heatmap** → Identified relationships between health factors."""

plt.figure(figsize=(8,5))
sns.countplot(y=df['admission_type'], order=df['admission_type'].value_counts().index, palette="viridis")
plt.title("Types of Admissions")
plt.xlabel("Count")
plt.ylabel("Admission Type")
plt.show()

"""**Box Plots** → Detected outliers in blood pressure & heart rate."""

plt.figure(figsize=(8,5))
sns.scatterplot(x=df['heart_rate'], y=df['blood_pressure'], hue=df['test_results'], palette="coolwarm")
plt.title("Heart Rate vs. Blood Pressure Analysis")
plt.xlabel("Heart Rate")
plt.ylabel("Blood Pressure")
plt.legend(title="Test Results")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Encode categorical columns
label_encoders = {}
for col in cat_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Store encoders for future decoding

# Feature Selection
X = df.drop(columns=['test_results'])  # Features
y = df['test_results']  # Target Variable

# Splitting Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize Numerical Features
scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Train Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate Model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", linewidths=0.5)
plt.title("Correlation Between Features")
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x=df['blood_pressure'])
plt.title("Outliers in Blood Pressure Levels")
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x=df['heart_rate'])
plt.title("Outliers in Heart Rate")
plt.show()

"""**Regression Model (Linear Regression)**
 : Predict length of hospital stay based on patient health factors.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Select Features
X_reg = df[['age', 'heart_rate', 'blood_pressure', 'oxygen_level', 'temperature']]
y_reg = df['length_of_stay']

# Split Data
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# Train Model
reg_model = LinearRegression()
reg_model.fit(X_train_reg, y_train_reg)

# Predictions
y_pred_reg = reg_model.predict(X_test_reg)

# Evaluation
print("Mean Absolute Error:", mean_absolute_error(y_test_reg, y_pred_reg))
print("Mean Squared Error:", mean_squared_error(y_test_reg, y_pred_reg))

"""**Real-Time IoT Patient Monitoring Simulation**  : Simulated real-time patient vital readings (heart rate, BP, temperature, oxygen level)."""

import time
import random

def simulate_real_time_data():
    for _ in range(5):  # Simulate 5 readings
        new_data = {
            'age': random.randint(20, 90),
            'heart_rate': random.randint(60, 120),
            'blood_pressure': random.randint(80, 180),
            'oxygen_level': random.randint(85, 100),
            'temperature': round(random.uniform(35.5, 39.0), 1)
        }
        print("New Patient Data Received:", new_data)
        time.sleep(2)  # Simulate delay in IoT data transmission

simulate_real_time_data()

!pip install fpdf

from fpdf import FPDF

pdf = FPDF()
pdf.add_page()
pdf.set_font("Arial", size=12)

pdf.cell(200, 10, txt="IoT-Based Patient Monitoring System", ln=True, align='C')
pdf.ln(10)

pdf.cell(200, 10, txt="Key Findings:", ln=True)
pdf.multi_cell(0, 10, txt=f"- Dataset Size: {df.shape[0]} records\n- Average Length of Stay: {df['length_of_stay'].mean():.2f} days\n- Hospitalization Factors: Age, Heart Rate, Oxygen Levels impact the duration\n")

pdf.cell(200, 10, txt="Machine Learning Insights:", ln=True)
pdf.multi_cell(0, 10, txt=f"- Classification Model Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\n- Regression Model Error (MAE): {mean_absolute_error(y_test_reg, y_pred_reg):.2f} days\n")

pdf.cell(200, 10, txt="IoT Real-Time Monitoring:", ln=True)
pdf.multi_cell(0, 10, txt="- Simulated live data streaming from IoT devices\n- Alerts triggered for high heart rate or low oxygen\n")

pdf.output("IoT_Patient_Monitoring_Report.pdf")
print("PDF Report Generated!")

from fpdf import FPDF

pdf = FPDF()
pdf.add_page()
pdf.set_font("Arial", size=12)
pdf.cell(200, 10, "IoT Patient Monitoring Report", ln=True, align="C")

# Save the PDF
pdf.output("iot_report.pdf")  # Ensure this file name is used correctly

!ls

from google.colab import files
files.download("iot_report.pdf")  # Ensure this matches the saved file name